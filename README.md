# Granola MCP Server

Welcome to the Granola MCP Server – the AI-native backend for note-taking, research, and knowledge workflows.
Granola is a lifesaver for someone that has back-to-back meetings and I just wanted to extend it to have it work with my current workflows and LLMs and give it the context to do the best it can.


## What is MCP (Model Context Protocol)?

MCP stands for Model Context Protocol. It’s a backend protocol for managing, syncing, and serving context to AI models. Think of it as the “glue” that lets your AI agents understand, retrieve, and update knowledge in real time. MCP is all about context: so now your AI assistant is always up-to-date and knows what you know from your meetings.


## Getting Started

1. Clone this repo.
2. Install dependencies `pip install requirements.txt`
3. Configure your workspace in `/config/granola.json`.
4. Run `python main.py` to launch the MCP server.


## Contributing

Open to PRs, feedback, and wild ideas. If I break somethign, my bad



---

Built by Mohamed Sharif, someone who just wants to learn everything